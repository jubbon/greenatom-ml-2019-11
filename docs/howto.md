## Описание работы сервиса
Почти все компоненты сервиса работают в режиме демона, то есть постоянно запущены на хосте в ожидании внешних запросов к ним.
Для взаимодействия между компонентами, а также с пользователем сервиса применяется два основных типа коммункации - распределенная очередь
сообщений и API по протоколу HTTP. В качестве брокера сообщений используется Kafka (с сервисом координации ZooKeeper).

Данные о сотрудниках собираются из внешних систем с помощью так называемых фетчеров (сборщиков) - отдельных компонентов, отвечающих за получение, разбор и структуризацию информации. Например, компонент fetcher.active_directory извелекает данные о сотруднике из корпоративной службы каталогов
Active Directory, а компонент fetcher.vk - из страницы с профилем сотрудника в социальной сети ВКонтакте. Фетчеры осуществяют сбор данных о
сотрудниках с некоторой периодичностью, зависящей от важности источника данных, особенностей технологий обработки информации из этого источника и
других факторов. Например, запрос данных у сервисов *Microsoft Exchange* и *Skype for Business* может осуществляться ежесуточно, а из социальных
сетей - с периодичностью 2-3 недели или реже.

Собираемые фетчерами данные записываются в топики распределенной системы Kafka, откуда забираются компонентом *engine*. Каждый тип сборщика записывает
данные в отдельный топик. Это обусловлено тем, что данные от сборщиков имеют различную структуру и могут обрабатываться разными способами. Например,
данные, содержащие текст (электронная почта, сообщение в мессенджере и т.д.), необходимо дополнительно обработать с использованием движков NLP - для
извлечения именованных сущностей (имена и фамилии людей, наименования, географические названия мест и т.п) и вычисления тональности (негативная,
положительная или нейтральная). Компонент *engine* передает текстовые сообщения через HTTP API компонентам *rusentiment_elmo_twitter_cnn* (для
распознавния тональности) и deeppavlov_ner_rus_bert (для извлечения сущностей). После получения ответа дополнительная метаинформация о тексте добавляется к исходным данным. Данные с текстом сохраняются в файл (будут использоваться позднее для дообучения моделей NLP), а данные с метаинформацией и без непосредственно самого текста - в колоночную базу данных *ClickHouse*.

В качестве web-приложения в сервисе используется платформа *Streamlit*. Пользователь открывает в браузере страницу, которая разделена на две части.
Левая часть (которая называеися сайдбар) испоьзуется для фильтрации данных, основная часть - для отображения контента. При интерактивном
взаимодействии с пользователем (нажатии кнопоко, выборе значений из списка) приложение запрашивает необходимые данные. При этом, часть данных
загружается из Excel-файла *hr.xls* (содержит статическую, редкоизменяющуюся информацию о сотрудниках и организации), в то время как динамическая
информация, которая зависит от активности сотрудников, получается из *ClickHouse*. Сагрегированная и обработанная информация отображается в виджетах
основного окна приложения.

В окне информации о сотруднике пользователю доступны кнопки **"Подобрать экспертов"** и **"Рассчитать вероятность увольнения"**.

Кнопка **"Подобрать экспертов"** используется для получения списка экспертов про текущим проектам пользователя. При ее нажатии сервис вычисленяет наиболее вероятных
экспертов, формирует список из них и отправляет пользователю по электронной почте. Для отправки письма служит отдельный компонент *smtp*, который
извелекает задание на отправку из топика *email*, формирует почтовое сообщение и отправляет его на почтовый шлюз по протоколу SMTP.

Кнопка **"Рассчитать вероятность увольнения"** необходима для расчета вероятности увольнения сотрудника в ближайшие 3 месяца. Запрос на вычисление вероятности отправляется компоненту
*predictor*, где хранится предварительно обученная на тренировочных данных модель машинного обучения. При получении запроса компонент *predictor*
извелекает необходимую информацию из файла *hr.xls*, базы данных *ClickHouse* и вычисляет вероятность увольнения - решается задача логистической регрессии методом градиентного спуска на решающих деревьях. В качестве библиотеки используется *Yandex CatBoost*.