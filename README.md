# SmartHR
SmartHR - интеллектуальный сервис-помощник служб HR средних и крупных компаний.
Прототип разработан в рамках хакатона Гринатом-2019.

[Сборка и запуск сервиса](./docs/install.md)


## Описание компонентов сервиса
Все компоненты сервиса разбиты по отдельным Docker-контейнерам. При этом, каждый Docker-контейнер
содержит один и только один компонент сервиса. Контейнеры, равно как и компоненты, подразделяются
на две группы - системные контейнеры и непосредственно контейнеры с логикой сервиса. К системным
компонентам относятся следующие:
 - **kafka** (контейнер *bitnami/kafka*) - распределенная очередь сообщений, которая связывает между
 собой другие компоненты сервиса.
 - **zookeeper** (контейнер *bitnami/zookeeper*) - сервис координации, используемый сервисом **kafka**.
 - **clickhouse** (контейнер *yandex/clickhouse-server*) - аналитическая (колоночная) база данных, используемая
 для хранения информации о событиях с сотрудниками
 - **deeppavlov_ner_ontonotes** (контейнер *deeppavlov/base-cpu*) - API-сервис для распознавания тональности текста
 (отрицательная тональность, нейтральная тональность, положительная тональность)
 - **deeppavlov_ner_rus_bert** (контейнер *deeppavlov/base-cpu*) - API-сервис для распознавания именованных сущностей
 (ФИО, названия проектов и организаций, локаций и т.д.)

К компонентам, реализующим непосредственно логику сервиса, относятся:
 - **data** (контейнер *citylix-greenatom-ml/data*) - отвечает за генерацию фейковых данных для демонстрации работы сервиса,
 а также данных, используемых для тренировки и валидации модели машинного обучения (вероятность увольнения сотрудника).
 - **predictor** (контейнер *citylix-greenatom-ml/predictor*) - осуществляет тренировку модели машинного обучения (вероятность
 увольнения сотрудника) и
 - **engine** (контейнер *citylix-greenatom-ml/engine*)
 - **simulator** (контейнер *citylix-greenatom-ml/simulator*) - симулятор поведения сотрудников, который является ключевым компонентом
 "цифрового двойника"
 - **fetcher.ping** (контейнер *citylix-greenatom-ml/fetcher.ping*)
 - **fetcher.lync** (контейнер *citylix-greenatom-ml/fetcher.lync*) - отвечает за сборку данных о переписке сотрудников между собой
 через службу *Skype for Business* (ранее *Microsoft Lync*)
 - **fetcher.active_directory** (контейнер *citylix-greenatom-ml/fetcher.active_directory*) - отвечает за сборку данных из службы
 *Active Directory*
 - **fetcher.exchange** (контейнер *citylix-greenatom-ml/fetcher.exchange*) - отвечает за сборку данных из службы
 *Microsoft Exchange*
 - **fetcher.vk** (контейнер *citylix-greenatom-ml/fetcher.vk*) - выполняет сбор и структуризацию открытых данных о сотрудниках
 из социальной сети ВКонтакте
 - **fetcher.ok** (контейнер *citylix-greenatom-ml/fetcher.ok*) - выполняет сбор и структуризацию открытых данных о сотрудниках
 из социальной сети Одноклассники
 - **fetcher.fb** (контейнер *citylix-greenatom-ml/fetcher.fb*)  - выполняет сбор и структуризацию открытых данных о сотрудниках
 из социальной сети Facebook
 - **fetcher.instagram** (контейнер *citylix-greenatom-ml/fetcher.instagram*) - выполняет сбор и структуризацию открытых данных о сотрудниках
 из социальной сети Instagram
 - **smtp** (контейнер *citylix-greenatom-ml/smtp*) - отправляет сообщения по электронной почте
 - **www** (контейнер *citylix-greenatom-ml/www*) - web-приложение, обеспечивающее интерактивное взаимодействие сервиса с пользователем


## Описание работы сервиса
Почти все компоненты сервиса работают в режиме демона, то есть постоянно запущены на хосте в ожидании внешних запросов к ним.
Для взаимодействия между компонентами, а также с пользователем сервиса применяется два основных типа коммункации - распределенная очередь
сообщений и API по протоколу HTTP. В качестве брокера сообщений используется Kafka (с сервисом координации ZooKeeper).

Данные о сотрудниках собираются из внешних систем с помощью так называемых фетчеров (сборщиков) - отдельных компонентов, отвечающих за получение, разбор и структуризацию информации. Например, компонент fetcher.active_directory извелекает данные о сотруднике из корпоративной службы каталогов
Active Directory, а компонент fetcher.vk - из страницы с профилем сотрудника в социальной сети ВКонтакте. Фетчеры осуществяют сбор данных о
сотрудниках с некоторой периодичностью, зависящей от важности источника данных, особенностей технологий обработки информации из этого источника и
других факторов. Например, запрос данных у сервисов *Microsoft Exchange* и *Skype for Business* может осуществляться ежесуточно, а из социальных
сетей - с периодичностью 2-3 недели или реже.

Собираемые фетчерами данные записываются в топики распределенной системы Kafka, откуда забираются компонентом *engine*. Каждый тип сборщика записывает
данные в отдельный топик. Это обусловлено тем, что данные от сборщиков имеют различную структуру и могут обрабатываться разными способами. Например,
данные, содержащие текст (электронная почта, сообщение в мессенджере и т.д.), необходимо дополнительно обработать с использованием движков NLP - для
извлечения именованных сущностей (имена и фамилии людей, наименования, географические названия мест и т.п) и вычисления тональности (негативная,
положительная или нейтральная). Компонент *engine* передает текстовые сообщения через HTTP API компонентам *deeppavlov_ner_ontonotes* (для
распознавния тональности) и deeppavlov_ner_rus_bert (для извлечения сущностей). После получения ответа дополнительная метаинформация о тексте добавляется к исходным данным. Данные с текстом сохраняются в файл (будут использоваться позднее для дообучения моделей NLP), а данные с метаинформацией и без непосредственно самого текста - в колоночную базу данных *ClickHouse*.

В качестве web-приложения в сервисе используется платформа *Streamlit*. Пользователь открывает в браузере страницу, которая разделена на две части.
Левая часть (которая называеися сайдбар) испоьзуется для фильтрации данных, основная часть - для отображения контента. При интерактивном
взаимодействии с пользователем (нажатии кнопоко, выборе значений из списка) приложение запрашивает необходимые данные. При этом, часть данных
загружается из Excel-файла *hr.xls* (содержит статическую, редкоизменяющуюся информацию о сотрудниках и организации), в то время как динамическая
информация, которая зависит от активности сотрудников, получается из *ClickHouse*. Сагрегированная и обработанная информация отображается в виджетах
основного окна приложения.

В окне информации о сотруднике пользователю доступны кнопки **"Подобрать экспертов"** и **"Рассчитать вероятность увольнения"**.

Кнопка **"Подобрать экспертов"** используется для получения списка экспертов про текущим проектам пользователя. При ее нажатии сервис вычисленяет наиболее вероятных
экспертов, формирует список из них и отправляет пользователю по электронной почте. Для отправки письма служит отдельный компонент *smtp*, который
извелекает задание на отправку из топика *email*, формирует почтовое сообщение и отправляет его на почтовый шлюз по протоколу SMTP.

Кнопка **"Рассчитать вероятность увольнения"** необходима для расчета вероятности увольнения сотрудника в ближайшие 3 месяца. Запрос на вычисление вероятности отправляется компоненту
*predictor*, где хранится предварительно обученная на тренировочных данных модель машинного обучения. При получении запроса компонент *predictor*
извелекает необходимую информацию из файла *hr.xls*, базы данных *ClickHouse* и вычисляет вероятность увольнения - решается задача логистической регрессии методом градиентного спуска на решающих деревьях. В качестве библиотеки используется *Yandex CatBoost*.